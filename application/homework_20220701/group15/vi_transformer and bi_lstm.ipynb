{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于多模态多特征的证券市场股票涨跌情况预测任务\n",
    "\n",
    "在本任务中，我们通过华为开源自研AI框架MindSpore搭建起了基于多模态多特征的深度学习模型，从图像（img）和文本（txt）两种信息载体出发，结合市场主体消息、股票价格呈现、股票技术分析等多种渠道，对证券市场股票（以上证50指数为例）的涨跌情况进行预测性分析。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型简介\n",
    "\n",
    "在模型设计上，我们主要基于vit-transformer和lstm两种模型构建，对图像和文本数据集进行结构化处理并输入到多模态模型中进行训练。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据处理\n",
    "\n",
    "开始实验之前，请确保本地已经安装了Python环境并安装了MindSpore框架和MindSpore Vision套件。\n",
    "\n",
    "### 数据准备\n",
    "\n",
    "\n",
    "本文研究需要获取上证50指数在每个交易日分别以日和以分钟为频率的历史交易数据，以及上证50指数成分股相关的新闻文本数据，以上数据的时间区间为2012年1月1日至2022年4月25日。\n",
    "\n",
    "表 5 上证50指数数据集统计\n",
    "| |训练集|训练集|训练集|测试集|测试集|测试集|\n",
    "|-|-|-|-|-|-|-|\n",
    "| |涨|跌|合计|涨|跌|合计|\n",
    "|交易行情图|1017|987|2004|258|243|501|\n",
    "|相关新闻天数|958|938|1896|254|240|494|\n",
    "\n",
    "本文采用的数据集包括两个部分：上证50指数历史交易数据和财经金融新闻文本数据。\n",
    "#### 图像数据\n",
    "其中，我们从聚宽平台获取2012年1月4日~2022年4月25日的股票交易数据，共2505个交易日的日频与分钟频的历史数据，其中前2004个交易日的数据所生成的折线图为训练集，后501个交易日的数据所生成的折线图为测试集。\n",
    "\n",
    "* 股票收盘价折现图即交易行情图的生成。基于股市K线图的观测原理，本文使用收盘价折线图作为股市的图形特征输入模型。文本通过使用聚宽平台开源的Python财经数据接口获取上证50指数的分钟线数据，根据分钟数据生成n天的股票收盘价折线图，并通过将背景色设置为黑色、缩小画布周边无效部分面积等方式，增加图中有效信息面积的占比。\n",
    "\n",
    "![图像部分信息数据](images/img_example.jpg)\n",
    "\n",
    "图 6 上证50指数连续14天收盘价折线图（2012-01-04至2012-01-30）\n",
    "\n",
    "通过特殊数据处理和加工手段，将证券市场动向、技术分析、价格情况等信息要素以时间为排列，构建起图像部分数据。并通过图像形式融合“上证50”的证券价格相关特征，形成模型图片部分输入内容（x）.\n",
    "以图6为例，折线图以一个交易日的时间（单位：分钟）为x轴，以收盘价价格（单位：元）为y轴，图中14条彩色的折线分别表示连续14天的收盘价变动情况。\n",
    "\n",
    "\n",
    "\n",
    "- 数据集大小：共2505个交易日的日频与分钟频的历史数据\n",
    "    - 训练集：前2004个交易日的数据所生成的折线图\n",
    "    - 测试集：后501个交易日的数据所生成的折线图\n",
    "- 数据格式：RGB\n",
    "\n",
    "#### 文本数据\n",
    "\n",
    "![文本部分信息数据](images/txt_example.png)\n",
    "\n",
    "通过专业财经类信息数据库（国泰安研究服务中心CSMAR系列数据库），经过相关性筛选和内容甄别，获取到《上海证券报》中每交易日开盘前的关于上证50指数成分股的相关报道，构建起文本部分数据。通过序列形式表达“上证50”证券的市场主体消息特征，形成模型文本部分输入内容（y）.\n",
    "\n",
    "![文本部分信息数据2](images/txt_example2.png)\n",
    "\n",
    "数据集路径结构如下。?\n",
    " ```bash\n",
    "└─newdataset/\n",
    "    ├─img/                \n",
    "    └─text/\n",
    "        └─log/  \n",
    "    \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据预处理及数据加载\n",
    "\n",
    "实验选择上证50指数作为股指预测的研究对象，其中基本技术分析数据主要使用的是上证50指数每天的交易行情数据，如当天的成交量、最高价、最低价、昨收价、涨跌额、涨跌幅、成交额、开盘价、收盘价等，本项目选择以当天的收盘价为交易行情数据。\n",
    "\n",
    "表 1 未经处理的部分行情数据\n",
    "| 日期 | 开盘价 | 收盘价 | 最高价 | 最低价 | 成交量 | 成交额 |\n",
    "| --- | --- | --- | --- | --- | --- | --- |\n",
    "|2012/1/4 | 1628.17 | 1595.12 | 1631.26 | 1594.42 | 1282270500 | 11591786058|\n",
    "|2012/1/5 | 1591.24 | 1596.59 | 1622.84 | 1590.54 | 1807836500 | 15109105146|\n",
    "|2012/1/6 | 1595.73 | 1608.36 | 1609.21 | 1588.6 | 1386997300 | 11459377051|\n",
    "|2012/1/9 | 1608.49 | 1659.05 | 1659.58 | 1598.39 | 2162757900 | 20009493676|\n",
    "|2012/1/10 | 1658.2 | 1704.74 | 1707.6 | 1655.3 | 2851741700 | 26442594973|\n",
    "|2012/1/11 | 1703.65 | 1694.26 | 1709.89 | 1686.64 | 1843090600 |18803937162|\n",
    "\n",
    "这些数据可以通过使用聚宽平台开源的Python财经数据接口来获取。首先利用接口获得上证50指数在时间区间范围内的日频行情数据，生成导出csv文件后，将日期数据与对应的收盘价数据保留，再使公式（16）计算第二天收盘价相比较于第一天的收盘价的涨跌幅度，若大于或者等于0则为涨势，标签记为1；若小于0则为跌势，标签记为0。\n",
    "\n",
    "其中change为收盘价的涨跌幅度，closei为第一天的收盘价，closei + 1为第二天的收盘价。\n",
    "\n",
    "表 2 以收盘价为基本技术分析数据的部分行情数据\n",
    "| 日期 | 收盘价 | 标签 |\n",
    "| --- | --- | --- |\n",
    "|2012/1/4 | 1595.12 | - |\n",
    "|2012/1/5 | 1596.59 | 1 |\n",
    "|2012/1/6 | 1608.36 | 1 |\n",
    "|2012/1/9 | 1659.05 | 1 |\n",
    "|2012/1/10 | 1704.74 | 1 |\n",
    "|2012/1/11 | 1694.26 | 0 |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 图片数据\n",
    "\n",
    "借助Dataset中map方法，实现对img列的数据预处理，将图像通道由H-W-C转变为C-H-W，并实现裁剪等图像操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import mindspore.dataset as ds\n",
    "\n",
    "def get_all_files(file_path,image_size):\n",
    "    \"\"\"\n",
    "    获取图片路径及其标签\n",
    "    :param file_path: a sting, 图片所在目录\n",
    "    :param is_random: True or False, 是否乱序\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    image_list = []\n",
    "    label_list = []\n",
    "    print(\"loading data start....\")\n",
    "    for item in os.listdir(file_path):\n",
    "        item_path = file_path + '/' + item\n",
    "        item_label = item.split('：')[1]\n",
    "        item_label=int(item_label.split('.')[0])\n",
    "        \n",
    "        img = Image.open(item_path)\n",
    "        arr = np.asarray(img, dtype=\"float32\")\n",
    "        arr.resize((image_size, image_size, 3),refcheck=False)\n",
    "        arr=arr/255\n",
    "        image_list.append(arr)\n",
    "        if(item_label==-1):\n",
    "            label_list.append(0)\n",
    "        else:\n",
    "            label_list.append(1)\n",
    "        # label_list.append(item_label)\n",
    "\n",
    "    label_list=np.array(label_list)\n",
    "    image_list=np.array(image_list)\n",
    "    print(\"loading data ok....\")\n",
    "    print(\"lable_list:\"+str(label_list[0:5]))\n",
    "    print(\"images_list:\"+str(image_list[0]))\n",
    "    return image_list, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_transform(dataset, resize):\n",
    "\n",
    "    mean = [0.485 * 255, 0.456 * 255, 0.406 * 255]\n",
    "    std = [0.229 * 255, 0.224 * 255, 0.225 * 255]\n",
    "\n",
    "#     trans = [\n",
    "#              c_transforms.Resize([resize, resize]),\n",
    "#              c_transforms.Normalize(mean=mean, std=std),\n",
    "#              c_transforms.HWC2CHW()]\n",
    "    trans = [c_transforms.HWC2CHW()]\n",
    "\n",
    "    dataset = dataset.map(operations=trans,\n",
    "                          input_columns=\"img\",\n",
    "                          num_parallel_workers=1)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 文本数据\n",
    "\n",
    "通过词典构建、词向量表示、短文本填充和长文本裁剪等文本处理手段对不定长文本进行数据预处理，并构建起文本的预训练词向量表示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text/load_data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from itertools import accumulate\n",
    "from operator import itemgetter\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['font.sans-serif']=['SimHei']\n",
    "\n",
    "BASE_DIR = \"newdataset/text/log\"\n",
    "\n",
    "KERAS_MODEL_SAVE_PATH = '%s/Bi-LSTM-4-NER.h5' % BASE_DIR\n",
    "WORD_DICTIONARY_PATH = '%s/word_dictionary.pk' % BASE_DIR\n",
    "InVERSE_WORD_DICTIONARY_PATH = '%s/inverse_word_dictionary.pk' % BASE_DIR\n",
    "LABEL_DICTIONARY_PATH = '%s/label_dictionary.pk' % BASE_DIR\n",
    "OUTPUT_DICTIONARY_PATH = '%s/output_dictionary.pk' % BASE_DIR\n",
    "\n",
    "CONSTANTS = [\n",
    "             KERAS_MODEL_SAVE_PATH,\n",
    "             InVERSE_WORD_DICTIONARY_PATH,\n",
    "             WORD_DICTIONARY_PATH,\n",
    "             LABEL_DICTIONARY_PATH,\n",
    "             OUTPUT_DICTIONARY_PATH\n",
    "             ]\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    data = pd.read_csv(\"newdataset/text/total.csv\")\n",
    "\n",
    "    text=data['Title']\n",
    "    input_data = list()\n",
    "\n",
    "    number=0\n",
    "    for i in range(0,len(text)-1):\n",
    "        for j in range(1, len(text[i]) - 1):\n",
    "            text_data = list()\n",
    "            text_data.append(number)\n",
    "            text_data.append(text[i][j])\n",
    "            input_data.append(text_data)\n",
    "        number+=1\n",
    "    input_data = pd.DataFrame(input_data,columns=['number', 'newColumn'])\n",
    "    input_data=input_data[['number', 'newColumn']]\n",
    "    return input_data\n",
    "\n",
    "\n",
    "\n",
    "# 数据查看\n",
    "def data_review():\n",
    "\n",
    "    # 数据导入\n",
    "    input_data = load_data()\n",
    "\n",
    "    # 基本的数据review\n",
    "    sent_num = input_data['number'].astype(np.int).max()\n",
    "    print(\"一共有%s个句子。\\n\"%sent_num)\n",
    "\n",
    "    vocabulary = input_data['newColumn'].unique()\n",
    "    print(\"一共有%d个单词。\"%len(vocabulary))\n",
    "    print(\"前10个单词为：%s.\\n\"%vocabulary[:11])\n",
    "\n",
    "    # pos_arr = input_data['pos'].unique()\n",
    "    # print(\"单词的词性列表：%s.\\n\"%pos_arr)\n",
    "    #\n",
    "    # ner_tag_arr = input_data['tag'].unique()\n",
    "    # print(\"NER的标注列表：%s.\\n\" % ner_tag_arr)\n",
    "\n",
    "    df = input_data[['number', 'newColumn']].groupby('number').count()\n",
    "    sent_len_list = df['newColumn'].tolist()\n",
    "    print(\"句子长度及出现频数字典：\\n%s.\" % dict(Counter(sent_len_list)))\n",
    "\n",
    "    # 绘制句子长度及出现频数统计图\n",
    "    sort_sent_len_dist = sorted(dict(Counter(sent_len_list)).items(), key=itemgetter(0))\n",
    "    sent_no_data = [item[0] for item in sort_sent_len_dist]\n",
    "    sent_count_data = [item[1] for item in sort_sent_len_dist]\n",
    "    plt.bar(sent_no_data, sent_count_data)\n",
    "    plt.title(\"句子长度及出现频数统计图\")\n",
    "    plt.xlabel(\"句子长度\")\n",
    "    plt.ylabel(\"句子长度出现的频数\")\n",
    "    plt.savefig(\"%s/句子长度及出现频数统计图.png\" % BASE_DIR)\n",
    "    plt.show()\n",
    "\n",
    "    # 绘制句子长度累积分布函数(CDF)\n",
    "    sent_pentage_list = [(count/sent_num) for count in accumulate(sent_count_data)]\n",
    "\n",
    "    # 寻找分位点为quantile的句子长度\n",
    "    quantile = 0.95\n",
    "    print(list(sent_pentage_list))\n",
    "    index=0\n",
    "    for length, per in zip(sent_no_data, sent_pentage_list):\n",
    "        if per>=quantile:\n",
    "            index = length\n",
    "            break\n",
    "    print(\"\\n分位点为%s的句子长度:%d.\" % (quantile, index))\n",
    "\n",
    "    # 绘制CDF\n",
    "    plt.plot(sent_no_data, sent_pentage_list)\n",
    "    plt.hlines(quantile, 0, index, colors=\"c\", linestyles=\"dashed\")\n",
    "    plt.vlines(index, 0, quantile, colors=\"c\", linestyles=\"dashed\")\n",
    "    plt.text(0, quantile, str(quantile))\n",
    "    plt.text(index, 0, str(index))\n",
    "    plt.title(\"句子长度累积分布函数图\")\n",
    "    plt.xlabel(\"句子长度\")\n",
    "    plt.ylabel(\"句子长度累积频率\")\n",
    "    plt.savefig(\"%s/句子长度累积分布函数图.png\" % BASE_DIR)\n",
    "    plt.show()\n",
    "\n",
    "# 数据处理\n",
    "def data_processing():\n",
    "    # 数据导入\n",
    "    input_data = load_data()\n",
    "    print(\"load data over.....\")\n",
    "\n",
    "    # 标签及词汇表\n",
    "    labels, vocabulary = list(input_data['number'].unique()), list(input_data['newColumn'].unique())\n",
    "\n",
    "    # 字典列表\n",
    "    word_dictionary = {word: i+1 for i, word in enumerate(vocabulary)}\n",
    "    inverse_word_dictionary = {i+1: word for i, word in enumerate(vocabulary)}\n",
    "    # label_dictionary = {label: i+1 for i, label in enumerate(labels)}\n",
    "    # output_dictionary = {i+1: labels for i, labels in enumerate(labels)}\n",
    "\n",
    "    dict_list = [word_dictionary, inverse_word_dictionary]\n",
    "\n",
    "    # 保存为pickle形式\n",
    "    for dict_item, path in zip(dict_list, CONSTANTS[1:]):\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(dict_item, f)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     load_data()\n",
    "#     data_review()\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据集结构化生成\n",
    "\n",
    "通过mindspore框架中GeneratorDataset（）方法，构建起[“img”,“txt”,“lable”]的三元数据集Dataset。\n",
    "\n",
    "其中，通过自定义IMDBData类，生成关于{img,txt,lable}的可迭代对象，用于GeneratorDataset（）方法中source传参。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMDBData\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class IMDBData():\n",
    "    def __init__(self,img,text,lable):\n",
    "        self.text=[]\n",
    "        self.lable=[]\n",
    "        self.img=[]\n",
    "        for i in range(0,len(lable)):\n",
    "            self.text.append(text[i])\n",
    "            self.lable.append(lable[i])\n",
    "            self.img.append(img[i])\n",
    "    def __getitem__(self, idx):\n",
    "        return  self.img[idx],self.text[idx],self.lable[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据加载\n",
    "\n",
    "通过数据集加载接口加载数据集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data over.....\n",
      "len(x)3126\n",
      "len(x[0])1625\n",
      "vocab_size3506\n",
      "loading data start....\n",
      "loading data ok....\n",
      "lable_list:[0 0 1 0 1]\n",
      "images_list:[[[0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.02745098 0.         0.        ]\n",
      "  [0.00784314 0.01176471 0.        ]\n",
      "  [0.         0.01568628 0.        ]\n",
      "  ...\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]]\n",
      "\n",
      " [[0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.         0.         0.        ]\n",
      "  ...\n",
      "  [0.21568628 0.10196079 0.11764706]\n",
      "  [0.3882353  0.2627451  0.28235295]\n",
      "  [0.3529412  0.27058825 0.2509804 ]]\n",
      "\n",
      " [[0.24705882 0.14901961 0.17254902]\n",
      "  [0.11764706 0.01960784 0.04313726]\n",
      "  [0.04313726 0.         0.        ]\n",
      "  ...\n",
      "  [0.00392157 0.         0.        ]\n",
      "  [0.         0.00392157 0.        ]\n",
      "  [0.         0.01176471 0.        ]]]\n",
      "train_x_txt:[[  1   2   3 ...   0   0   0]\n",
      " [ 14  20  30 ...   0   0   0]\n",
      " [186 187 188 ...   0   0   0]\n",
      " [ 93   5 198 ...   0   0   0]\n",
      " [ 42  43  44 ...   0   0   0]]\n",
      "train_lable_one_hot:[[1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "    input_shape= 1625\n",
    "    resize=224\n",
    "    batch_size=15\n",
    "    test_dir=\"newdataset/img\"\n",
    "    #数据读入\n",
    "    txt, vocab_size, inverse_word_dictionary = input_data_for(input_shape)\n",
    "    image_train_batch, label_train_batch= get_all_files(test_dir, resize)\n",
    "    label_train_batch= np.eye(2, dtype=np.uint8)[label_train_batch]\n",
    "\n",
    "    if(len(image_train_batch)>len(txt)):\n",
    "        size=len(txt)\n",
    "    else:\n",
    "        size=len(image_train_batch)\n",
    "    end=int(size*0.8)\n",
    "\n",
    "    train_x_txt=txt[0:end]\n",
    "    test_x_txt=txt[end:size-1]\n",
    "    print(\"train_x_txt:\"+str(train_x_txt[0:5]))\n",
    "\n",
    "    train_x_img,train_y=image_train_batch[0:end],label_train_batch[0:end]\n",
    "    test_x_img,test_y=image_train_batch[end:size-1],label_train_batch[end:size-1]\n",
    "    print(\"train_lable_one_hot:\"+str(train_y[0:5]))\n",
    "    datesets=[]\n",
    "    for i in range(0,end,batch_size):\n",
    "        datesets.append([train_x_img[i:i+batch_size],train_x_txt[i:i+batch_size],train_y[i:i+batch_size]])\n",
    "    # # column_names = [\"img\",\"txt\",\"lable\"]\n",
    "    dataset = ds.GeneratorDataset(source=IMDBData(train_x_img,train_x_txt,train_y),column_names=[\"img\",\"txt\",\"lable\"])\n",
    "    dataset = infer_transform(dataset, resize)\n",
    "    dataset = dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建网络\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vit-transformer 模型\n",
    "\n",
    "借助于mindspore框架，依次完成PatchEmbedding、Attention、TransformerEncoder等Vision Transformer（ViT）模型的基础模块类\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attention模块\n",
    "\n",
    "核心内容是为输入向量的每个单词学习一个权重。通过给定一个任务相关的查询向量Query向量，计算Query和各个Key的相似性或者相关性得到注意力分布，即得到每个Key对应Value的权重系数，然后对Value进行加权求和得到最终的Attention数值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindspore import nn, ops\n",
    "import mindspore as ms\n",
    "class Attention(nn.Cell):\n",
    "    def __init__(self,\n",
    "                 dim: int,\n",
    "                 num_heads: int = 8,\n",
    "                 keep_prob: float = 1.0,\n",
    "                 attention_keep_prob: float = 1.0):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        self.num_heads = num_heads\n",
    "        head_dim = dim // num_heads\n",
    "        self.scale = ms.Tensor(head_dim ** -0.5)\n",
    "\n",
    "        self.qkv = nn.Dense(dim, dim * 3)\n",
    "        self.attn_drop = nn.Dropout(attention_keep_prob)\n",
    "        self.out = nn.Dense(dim, dim)\n",
    "        self.out_drop = nn.Dropout(keep_prob)\n",
    "\n",
    "        self.mul = ops.Mul()\n",
    "        self.reshape = ops.Reshape()\n",
    "        self.transpose = ops.Transpose()\n",
    "        self.unstack = ops.Unstack(axis=0)\n",
    "        self.attn_matmul_v = ops.BatchMatMul()\n",
    "        self.q_matmul_k = ops.BatchMatMul(transpose_b=True)\n",
    "        self.softmax = nn.Softmax(axis=-1)\n",
    "\n",
    "    def construct(self, x):\n",
    "        \"\"\"Attention construct.\"\"\"\n",
    "        b, n, c = x.shape\n",
    "\n",
    "        # 最初的输入向量首先会经过Embedding层映射成Q(Query)，K(Key)，V(Value)三个向量\n",
    "        # 由于是并行操作，所以代码中是映射成为dim*3的向量然后进行分割\n",
    "        qkv = self.qkv(x)\n",
    "\n",
    "        #多头注意力机制就是将原本self-Attention处理的向量分割为多个Head进行处理\n",
    "        qkv = self.reshape(qkv, (b, n, 3, self.num_heads, c // self.num_heads))\n",
    "        qkv = self.transpose(qkv, (2, 0, 3, 1, 4))\n",
    "        q, k, v = self.unstack(qkv)\n",
    "\n",
    "        # 自注意力机制的自注意主要体现在它的Q，K，V都来源于其自身\n",
    "        # 也就是该过程是在提取输入的不同顺序的向量的联系与特征\n",
    "        # 最终通过不同顺序向量之间的联系紧密性（Q与K乘积经过Softmax的结果）来表现出来\n",
    "        attn = self.q_matmul_k(q, k)\n",
    "        attn = self.mul(attn, self.scale)\n",
    "        attn = self.softmax(attn)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        # 其最终输出则是通过V这个映射后的向量与QK经过Softmax结果进行weight sum获得\n",
    "        # 这个过程可以理解为在全局上进行自注意表示\n",
    "        out = self.attn_matmul_v(attn, v)\n",
    "        out = self.transpose(out, (0, 2, 1, 3))\n",
    "        out = self.reshape(out, (b, n, c))\n",
    "        out = self.out(out)\n",
    "        out = self.out_drop(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   #### PatchEmbedding模块\n",
    "\n",
    "在ViT模型中：\n",
    "\n",
    "通过将输入图像在每个channel上划分为16*16个patch，这一步是通过卷积操作来完成的，当然也可以人工进行划分，但卷积操作也可以达到目的同时还可以进行一次而外的数据处理；例如一幅输入224 x 224的图像，首先经过卷积处理得到16 x 16个patch，那么每一个patch的大小就是14 x 14。\n",
    "\n",
    "再将每一个patch的矩阵拉伸成为一个1维向量，从而获得了近似词向量堆叠的效果。上一步得到的14 x 14的patch就转换为长度为196的向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchEmbedding(nn.Cell):\n",
    "    MIN_NUM_PATCHES = 4\n",
    "    def __init__(self,\n",
    "                 image_size: int = 224,\n",
    "                 patch_size: int = 16,\n",
    "                 embed_dim: int = 768,\n",
    "                 input_channels: int = 3):\n",
    "        super(PatchEmbedding, self).__init__()\n",
    "\n",
    "        self.image_size = image_size\n",
    "        self.patch_size = patch_size\n",
    "        self.num_patches = (image_size // patch_size) ** 2\n",
    "\n",
    "        # 通过将输入图像在每个channel上划分为16*16个patch\n",
    "        self.conv = nn.Conv2d(input_channels, embed_dim, kernel_size=patch_size, stride=patch_size, has_bias=True)\n",
    "        self.reshape = P.Reshape()\n",
    "        self.transpose = P.Transpose()\n",
    "\n",
    "    def construct(self, x):\n",
    "        \"\"\"Path Embedding construct.\"\"\"\n",
    "        x = self.conv(x)\n",
    "        b, c, h, w = x.shape\n",
    "\n",
    "        # 再将每一个patch的矩阵拉伸成为一个1维向量，从而获得了近似词向量堆叠的效果；\n",
    "        x = self.reshape(x, (b, c, h * w))\n",
    "        x = self.transpose(x, (0, 2, 1))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformer Encoder\n",
    "\n",
    "在了解了Self-Attention结构之后，通过与Feed Forward，Residual Connection等结构的拼接就可以形成Transformer的基础结构，接下来就利用Self-Attention来构建ViT模型中的TransformerEncoder部分，类似于构建了一个Transformer的编码器部分，将TransformerEncoder结构和一个多层感知器（MLP）结合，就构成了ViT模型的backbone部分。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  mindspore as ms\n",
    "import mindspore.nn as nn\n",
    "import mindspore.train.callback as callback\n",
    "from mindvision.classification.models import FeedForward, ResidualCell\n",
    "class TransformerEncoder(nn.Cell):\n",
    "    def __init__(self,\n",
    "                 dim: int,\n",
    "                 num_layers: int,\n",
    "                 num_heads: int,\n",
    "                 mlp_dim: int,\n",
    "                 keep_prob: float = 1.,\n",
    "                 attention_keep_prob: float = 1.0,\n",
    "                 drop_path_keep_prob: float = 1.0,\n",
    "                 activation: nn.Cell = nn.GELU,\n",
    "                 norm: nn.Cell = nn.LayerNorm):\n",
    "        super(TransformerEncoder, self).__init__()\n",
    "        layers = []\n",
    "\n",
    "        # 从vit_architecture图可以发现，多个子encoder的堆叠就完成了模型编码器的构建\n",
    "        # 在ViT模型中，依然沿用这个思路，通过配置超参数num_layers，就可以确定堆叠层数\n",
    "        for _ in range(num_layers):\n",
    "            normalization1 = norm((dim,))\n",
    "            normalization2 = norm((dim,))\n",
    "            attention = Attention(dim=dim,\n",
    "                                  num_heads=num_heads,\n",
    "                                  keep_prob=keep_prob,\n",
    "                                  attention_keep_prob=attention_keep_prob)\n",
    "\n",
    "            feedforward = FeedForward(in_features=dim,\n",
    "                                      hidden_features=mlp_dim,\n",
    "                                      activation=activation,\n",
    "                                      keep_prob=keep_prob)\n",
    "\n",
    "            # ViT模型中的基础结构与标准Transformer有所不同\n",
    "            # 主要在于Normalization的位置是放在Self-Attention和Feed Forward之前\n",
    "            # 其他结构如Residual Connection，Feed Forward，Normalization都如Transformer中所设计\n",
    "            layers.append(\n",
    "                nn.SequentialCell([\n",
    "                    # Residual Connection，Normalization的结构可以保证模型有很强的扩展性\n",
    "                    # 保证信息经过深层处理不会出现退化的现象，这是Residual Connection的作用\n",
    "                    # Normalization和dropout的应用可以增强模型泛化能力\n",
    "                    ResidualCell(nn.SequentialCell([normalization1,\n",
    "                                                    attention])),\n",
    "\n",
    "                    ResidualCell(nn.SequentialCell([normalization2,\n",
    "                                                    feedforward]))\n",
    "                ])\n",
    "            )\n",
    "        self.layers = nn.SequentialCell(layers)\n",
    "\n",
    "    def construct(self, x):\n",
    "        \"\"\"Transformer construct.\"\"\"\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 整体构建ViT\n",
    "\n",
    "以下代码构建了一个完整的ViT模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "class ViT(nn.Cell):\n",
    "    def __init__(self,\n",
    "                 image_size: int = 224,\n",
    "                 input_channels: int = 3,\n",
    "                 patch_size: int = 16,\n",
    "                 embed_dim: int = 768,\n",
    "                 num_layers: int = 12,\n",
    "                 num_heads: int = 12,\n",
    "                 mlp_dim: int = 3072,\n",
    "                 keep_prob: float = 1.0,\n",
    "                 attention_keep_prob: float = 1.0,\n",
    "                 drop_path_keep_prob: float = 1.0,\n",
    "                 activation: nn.Cell = nn.GELU,\n",
    "                 norm: Optional[nn.Cell] = nn.LayerNorm,\n",
    "                 pool: str = 'cls') -> None:\n",
    "        super(ViT, self).__init__()\n",
    "\n",
    "        self.patch_embedding = PatchEmbedding(image_size=image_size,\n",
    "                                              patch_size=patch_size,\n",
    "                                              embed_dim=embed_dim,\n",
    "                                              input_channels=input_channels)\n",
    "        num_patches = self.patch_embedding.num_patches\n",
    "\n",
    "        # 此处增加class_embedding和pos_embedding，如果不是进行分类任务\n",
    "        # 可以只增加pos_embedding，通过pool参数进行控制\n",
    "        self.cls_token = init(init_type=Normal(sigma=1.0),\n",
    "                              shape=(1, 1, embed_dim),\n",
    "                              dtype=ms.float32,\n",
    "                              name='cls',\n",
    "                              requires_grad=True)\n",
    "\n",
    "        # pos_embedding也是一组可以学习的参数，会被加入到经过处理的patch矩阵中\n",
    "        self.pos_embedding = init(init_type=Normal(sigma=1.0),\n",
    "                                  shape=(1, num_patches + 1, embed_dim),\n",
    "                                  dtype=ms.float32,\n",
    "                                  name='pos_embedding',\n",
    "                                  requires_grad=True)\n",
    "\n",
    "        # axis=1定义了会在向量的开头加入class_embedding\n",
    "        self.concat = P.Concat(axis=1)\n",
    "\n",
    "        self.pool = pool\n",
    "        self.pos_dropout = nn.Dropout(keep_prob)\n",
    "        self.norm = norm((embed_dim,))\n",
    "        self.tile = P.Tile()\n",
    "        self.transformer = TransformerEncoder(dim=embed_dim,\n",
    "                                              num_layers=num_layers,\n",
    "                                              num_heads=num_heads,\n",
    "                                              mlp_dim=mlp_dim,\n",
    "                                              keep_prob=keep_prob,\n",
    "                                              attention_keep_prob=attention_keep_prob,\n",
    "                                              drop_path_keep_prob=drop_path_keep_prob,\n",
    "                                              activation=activation,\n",
    "                                              norm=norm)\n",
    "\n",
    "    def construct(self, x):\n",
    "        \"\"\"ViT construct.\"\"\"\n",
    "        x = self.patch_embedding(x)\n",
    "\n",
    "        # class_embedding主要借鉴了BERT模型的用于文本分类时的思想\n",
    "        # 在每一个word vector之前增加一个类别值，通常是加在向量的第一位\n",
    "        cls_tokens = self.tile(self.cls_token, (x.shape[0], 1, 1))\n",
    "        x = self.concat((cls_tokens, x))\n",
    "        x += self.pos_embedding\n",
    "\n",
    "        x = self.pos_dropout(x)\n",
    "        x = self.transformer(x)\n",
    "        x = self.norm(x)\n",
    "\n",
    "        # 增加的class_embedding是一个可以学习的参数，经过网络的不断训练\n",
    "        # 最终以输出向量的第一个维度的输出来决定最后的输出类别；\n",
    "        x = x[:, 0]\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi- LSTM模型\n",
    "\n",
    "使用mindspore框架中LSTM实现双向LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bi_LSTM_model\n",
    "import pickle\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "from keras.models import load_model\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Bidirectional, LSTM, Dense, TimeDistributed, Dropout, Masking\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "\n",
    "#from text.load_data import CONSTANTS, load_data, data_processing, BASE_DIR\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def input_data_for_model(input_shape):\n",
    "\n",
    "    # 数据导入\n",
    "    input_data = load_data()\n",
    "    # 数据处理\n",
    "    data_processing()\n",
    "    # 导入字典\n",
    "    with open(CONSTANTS[1], 'rb') as f:\n",
    "        word_dictionary = pickle.load(f)\n",
    "    with open(CONSTANTS[2], 'rb') as f:\n",
    "        inverse_word_dictionary = pickle.load(f)\n",
    "    with open(CONSTANTS[3], 'rb') as f:\n",
    "        label_dictionary = pickle.load(f)\n",
    "    with open(CONSTANTS[4], 'rb') as f:\n",
    "        output_dictionary = pickle.load(f)\n",
    "    vocab_size = len(word_dictionary.keys())\n",
    "    label_size = len(label_dictionary.keys())\n",
    "\n",
    "    # 处理输入数据\n",
    "    aggregate_function = lambda input: [(word, label) for word,label in\n",
    "                                            zip(input['word'].values.tolist(),\n",
    "                                                input['tag'].values.tolist())]\n",
    "\n",
    "    grouped_input_data = input_data.groupby('sent_no').apply(aggregate_function)\n",
    "    sentences = [sentence for sentence in grouped_input_data]\n",
    "\n",
    "    x = [[word_dictionary[word[0]] for word in sent] for sent in sentences]\n",
    "    x = pad_sequences(maxlen=input_shape, sequences=x, padding='post', value=0)\n",
    "    y = [[label_dictionary[word[1]] for word in sent] for sent in sentences]\n",
    "    y = pad_sequences(maxlen=input_shape, sequences=y, padding='post', value=0)\n",
    "    y = [np_utils.to_categorical(label, num_classes=label_size+1) for label in y]\n",
    "    return x, y, output_dictionary, vocab_size, label_size, inverse_word_dictionary\n",
    "\n",
    "def draw_train(history):\n",
    "        \n",
    "        plt.plot(history.history['accuracy'],'r-')\n",
    "        plt.plot(history.history['val_accuracy'],'b:')\n",
    "        plt.title('Model accuracy')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train','Test'], loc='upper left')\n",
    "        plt.show()\n",
    "       \n",
    "        plt.plot(history.history['loss'],'r-')\n",
    "        plt.plot(history.history['val_loss'],'b:')\n",
    "        plt.title('Model loss')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.legend(['Train','Test'], loc='upper left')\n",
    "        plt.show()\n",
    "\n",
    "# # 定义深度学习模型：Bi-LSTM\n",
    "def create_Bi_LSTM(vocab_size, label_size, input_shape, output_dim, n_units, out_act, activation):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size + 1,\n",
    "                        output_dim=output_dim,\n",
    "                        input_length=input_shape,\n",
    "                        trainable=True,\n",
    "                        mask_zero=True))\n",
    "    model.add(LSTM(units=100,input_shape=(1500,128)))\n",
    "   \n",
    "    keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "    model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "   \n",
    "    keras.utils.plot_model(model, 'LSTM.png', show_shapes=True)\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "\n",
    "# 模型训练\n",
    "def model_train():\n",
    "    # 将数据集分为训练集和测试集，占比为9:1\n",
    "    input_shape = 1500\n",
    "    x, vocab_size, inverse_word_dictionary = input_data_for(input_shape)\n",
    "  \n",
    "    activation = 'selu'\n",
    "    out_act = 'softmax'\n",
    "    n_units = 128\n",
    "    batch_size = 186\n",
    "    epochs = 10\n",
    "    output_dim = 128\n",
    "    # 模型训练\n",
    "    lstm_model = create_Bi_LSTM(vocab_size, 19, input_shape, output_dim, n_units, out_act, activation)\n",
    "    lstm_model.summary()\n",
    "  \n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def model_test():\n",
    "    # 导入字典\n",
    "    with open(CONSTANTS[1], 'rb') as f:\n",
    "        word_dictionary = pickle.load(f)\n",
    "    with open(CONSTANTS[4], 'rb') as f:\n",
    "        output_dictionary = pickle.load(f)\n",
    "\n",
    "    x, y, output_dictionary, vocab_size, label_size, inverse_word_dictionary=input_data_for_model(40,\"D:\\\\conll\\\\data\\\\CoNLL-2003\\\\eng.testa\")\n",
    "    model_save_path = CONSTANTS[0]\n",
    "    lstm_model = load_model(model_save_path)\n",
    "    y_predict=lstm_model.predict(x)\n",
    "\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     model_train()\n",
    "#     # input_data_for(input_shape=1500)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 整体模型搭建\n",
    "\n",
    "通过toger函数完成整体模型类的搭建工作，具体在construct中体现模型的多输入特性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#together\n",
    "from mindspore.common.initializer import Normal\n",
    "from mindvision.classification.utils import init\n",
    "#from PatchEmbedding import PatchEmbedding\n",
    "#from TransformerEncoder import TransformerEncoder\n",
    "import mindspore as ms\n",
    "import mindspore.ops as P\n",
    "from mindspore import nn, ops\n",
    "from typing import Optional\n",
    "\n",
    "class toger(nn.Cell):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 num_tags,\n",
    "                 image_size,\n",
    "                 seq_length,\n",
    "                 embedding_dim: int = 32,\n",
    "                 hidden_dim: int = 64,\n",
    "                 padding_idx=0,\n",
    "                 patch_size : int=16,\n",
    "                 input_channels: int = 3,\n",
    "                 embed_dim: int = 768,\n",
    "                 num_layers: int = 12,\n",
    "                 num_heads: int = 12,\n",
    "                 mlp_dim: int = 3072,\n",
    "                 keep_prob: float = 1.0,\n",
    "                 attention_keep_prob: float = 1.0,\n",
    "                 drop_path_keep_prob: float = 1.0,\n",
    "                 activation: nn.Cell = nn.GELU,\n",
    "                 norm: Optional[nn.Cell] = nn.LayerNorm,\n",
    "                 pool: str = 'cls'):\n",
    "        super(toger,self).__init__()\n",
    "        self.patch_embedding = PatchEmbedding(image_size=image_size,\n",
    "                                              patch_size=patch_size,\n",
    "                                              embed_dim=embed_dim,\n",
    "                                              input_channels=input_channels)\n",
    "        num_patches = self.patch_embedding.num_patches\n",
    "\n",
    "        # 此处增加class_embedding和pos_embedding，如果不是进行分类任务\n",
    "        # 可以只增加pos_embedding，通过pool参数进行控制\n",
    "        self.cls_token = init(init_type=Normal(sigma=1.0),\n",
    "                              shape=(1, 1, embed_dim),\n",
    "                              dtype=ms.float32,\n",
    "                              name='cls',\n",
    "                              requires_grad=True)\n",
    "\n",
    "        # pos_embedding也是一组可以学习的参数，会被加入到经过处理的patch矩阵中\n",
    "        self.pos_embedding = init(init_type=Normal(sigma=1.0),\n",
    "                                  shape=(1, num_patches + 1, embed_dim),\n",
    "                                  dtype=ms.float32,\n",
    "                                  name='pos_embedding',\n",
    "                                  requires_grad=True)\n",
    "\n",
    "        # axis=1定义了会在向量的开头加入class_embedding\n",
    "        self.concat = P.Concat(axis=1)\n",
    "\n",
    "        self.pool = pool\n",
    "        self.pos_dropout = nn.Dropout(keep_prob)\n",
    "        self.norm = norm((embed_dim,))\n",
    "        self.tile = P.Tile()\n",
    "        self.transformer = TransformerEncoder(dim=embed_dim,\n",
    "                                              num_layers=num_layers,\n",
    "                                              num_heads=num_heads,\n",
    "                                              mlp_dim=mlp_dim,\n",
    "                                              keep_prob=keep_prob,\n",
    "                                              attention_keep_prob=attention_keep_prob,\n",
    "                                              drop_path_keep_prob=drop_path_keep_prob,\n",
    "                                              activation=activation,\n",
    "                                              norm=norm)\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=padding_idx)\n",
    "        self.seq_length=seq_length\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2, bidirectional=True, batch_first=True)\n",
    "        self.hidden2tag = nn.Dense(hidden_dim, hidden_dim * 2 , 'he_uniform')\n",
    "        self.Dense = nn.Dense(hidden_dim*6,hidden_dim * 2,'he_uniform')\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.sigmoid = ops.Sigmoid()\n",
    "\n",
    "    def construct(self, x,y):\n",
    "\n",
    "        \"\"\"ViT construct.\"\"\"\n",
    "        x = self.patch_embedding(x)\n",
    "\n",
    "        # class_embedding主要借鉴了BERT模型的用于文本分类时的思想\n",
    "        # 在每一个word vector之前增加一个类别值，通常是加在向量的第一位\n",
    "        cls_tokens = self.tile(self.cls_token, (x.shape[0], 1, 1))\n",
    "        x = self.concat((cls_tokens, x))\n",
    "        x += self.pos_embedding\n",
    "\n",
    "        x = self.pos_dropout(x)\n",
    "        x = self.transformer(x)\n",
    "        x = self.norm(x)\n",
    "\n",
    "        # 增加的class_embedding是一个可以学习的参数，经过网络的不断训练\n",
    "        # 最终以输出向量的第一个维度的输出来决定最后的输出类别；\n",
    "        img = x[:, 0]\n",
    "\n",
    "        y = self.embedding(y)\n",
    "        y, _ = self.lstm(y, seq_length=self.seq_length)\n",
    "        text = self.hidden2tag(y)\n",
    "\n",
    "        toge= self.concat((img, text))\n",
    "\n",
    "        toge=self.dropout(toge)\n",
    "        toge=self.Dense(toge)\n",
    "\n",
    "        return self.sigmoid(toge)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MyWithLossCell\n",
    "\n",
    "MyWithLossCell类用于模型与损失的链接（net_with_loss），实现对三元数据集损失计算的适配。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MyWithLossCell\n",
    "from mindspore.nn import Cell\n",
    "\n",
    "class MyWithLossCell(Cell):\n",
    "   def __init__(self, backbone, loss_fn):\n",
    "       super(MyWithLossCell, self).__init__(auto_prefix=False)\n",
    "       self._backbone = backbone\n",
    "       self._loss_fn = loss_fn\n",
    "\n",
    "   def construct(self, x, y, label):\n",
    "       out = self._backbone(x, y)\n",
    "       return self._loss_fn(out, label)\n",
    "\n",
    "   @property\n",
    "   def backbone_network(self):\n",
    "       return self._backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_one_epoch\n",
    "\n",
    "自定义train_one_epoch函数用于单步训练的梯度下降和权重更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Tuple\n",
    "\n",
    "import mindspore\n",
    "from mindspore.dataset import vision\n",
    "from mindvision.classification import ImageNet\n",
    "from mindvision.classification.dataset import Mnist\n",
    "from tqdm import tqdm\n",
    "\n",
    "#from MyWithLossCell import MyWithLossCell\n",
    "#from img.load_data import get_all_files\n",
    "#from text.Bi_LSTM_Model import input_data_for\n",
    "#from toge import toger\n",
    "import  mindspore as ms\n",
    "import mindspore.nn as nn\n",
    "from mindvision.engine.callback import LossMonitor\n",
    "from mindvision.engine.loss import CrossEntropySmooth\n",
    "#from IMDBData import IMDBData\n",
    "\n",
    "\n",
    "import mindspore.dataset as ds\n",
    "import numpy as np\n",
    "from mindspore.dataset.vision import c_transforms\n",
    "\n",
    "\n",
    "\n",
    "def train_one_epoch(model, dateset,bitch_size,epoch=0):\n",
    "    model.set_train()\n",
    "    total = bitch_size\n",
    "    loss_total = 0\n",
    "    step_total = 0\n",
    "    m=dateset.create_tuple_iterator()\n",
    "    with tqdm(total=total) as t:\n",
    "        t.set_description('Epoch %i' % epoch)\n",
    "        for i in dateset.create_tuple_iterator():\n",
    "            print(i)\n",
    "            loss = model(*i)\n",
    "            loss_total += loss.asnumpy()\n",
    "            step_total += 1\n",
    "            t.set_postfix(loss=loss_total/step_total)\n",
    "            t.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate函数\n",
    "\n",
    "自定义evaluate函数用于训练情况评估，并在训练过程中更新一个“最佳损失情况”变量（best_valid_loss）用于保留最佳模型的模型参数（save_checkpoint）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_dataset, criterion,bitch_size, epoch=0):\n",
    "    total = bitch_size\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    step_total = 0\n",
    "    model.set_train(False)\n",
    "\n",
    "    with tqdm(total=total) as t:\n",
    "        t.set_description('Epoch %i' % epoch)\n",
    "        for i in test_dataset:\n",
    "            predictions = model(i[0],i[1])\n",
    "            loss = criterion(predictions, i[2])\n",
    "            epoch_loss += loss.asnumpy()\n",
    "\n",
    "            acc = binary_accuracy(predictions.asnumpy(), i[1].asnumpy())\n",
    "            epoch_acc += acc\n",
    "\n",
    "            step_total += 1\n",
    "            t.set_postfix(loss=epoch_loss/step_total, acc=epoch_acc/step_total)\n",
    "            t.update(1)\n",
    "\n",
    "    return epoch_loss / total"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 损失函数\n",
    "\n",
    "选取二分类任务中常用的二分类交叉熵作为损失函数（nn.BCELoss）\n",
    "\n",
    "\n",
    " ![二分类交叉熵](images/math.png)\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义损失函数\n",
    "loss = nn.BCELoss(reduction='mean')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型实现\n",
    "\n",
    "采用TrainOneStepCell，用于实现单步训练，\n",
    "采用Adam优化器，\n",
    "采用mindspore框架的cosine_decay_lr实现动态的学习率调整，提高训练效率和成果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy(preds, y):\n",
    "    \"\"\"\n",
    "    计算每个batch的准确率\n",
    "    \"\"\"\n",
    "\n",
    "    # 对预测值进行四舍五入\n",
    "    rounded_preds = np.around(preds)\n",
    "    correct = (rounded_preds == y).astype(np.float32)\n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "\n",
    "\n",
    "\n",
    "def train():\n",
    "    # 定义超参数\n",
    "    epoch= 30\n",
    "    # momentum = 0.9\n",
    "    \n",
    "    hidden_dim=128\n",
    "    num_classes = 2\n",
    "    \n",
    "\n",
    "    cache_dir = Path.home() / '.mslog'\n",
    "\n",
    "\n",
    "\n",
    "    network = toger(vocab_size=1500,\n",
    "                         num_tags=num_classes,\n",
    "                         image_size=resize,\n",
    "                         seq_length=input_shape,\n",
    "                         hidden_dim=hidden_dim)\n",
    "    net_with_loss = MyWithLossCell(network, loss)\n",
    "\n",
    "    lr = nn.cosine_decay_lr(min_lr=float(0),\n",
    "                            max_lr=0.003,\n",
    "                            total_step=epoch * batch_size,\n",
    "                            step_per_epoch=batch_size,\n",
    "                            decay_epoch=90)\n",
    "\n",
    "    \n",
    "\n",
    "    optimizer = nn.Adam(network.trainable_params(), learning_rate=lr)\n",
    "\n",
    "    train_one_step = nn.TrainOneStepCell(net_with_loss, optimizer)\n",
    "\n",
    "    best_valid_loss = float('inf')\n",
    "    ckpt_file_name = os.path.join(cache_dir, 'sentiment-analysis.ckpt')\n",
    "    # ckpt_callback = mindspore.ModelCheckpoint(prefix='toger', directory='./ViT', config=ckpt_file_name)\n",
    "    \n",
    "    # 初始化模型\n",
    "    model = ms.Model(network, loss_fn=loss, optimizer=optimizer, metrics={\"acc\"})\n",
    "    # # 训练\n",
    "    # train_one_step.train(epoch_size,\n",
    "    #             dataset,\n",
    "    #             callbacks= LossMonitor(lr))\n",
    "\n",
    "    \n",
    "\n",
    "  \n",
    "\n",
    "def generator_multi_column():\n",
    "    for i in range(5):\n",
    "         return np.array([i]), np.array([[i, i + 1], [i + 2, i + 3]])\n",
    "\n",
    "def train_data(num):\n",
    "    x = np.array(np.random.rand(num,1))\n",
    "    y = x*2 + 1\n",
    "    return np.concatenate((x,y),axis=1)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|                                                                                  | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[  0/ 10], step:[    1/  157], loss:[3.904/3.904], time:123548.419 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[    2/  157], loss:[7.421/5.663], time:117884.310 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[    3/  157], loss:[6.310/5.878], time:109111.214 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[    4/  157], loss:[6.431/6.017], time:121945.406 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[    5/  157], loss:[2.788/5.371], time:105975.384 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[    6/  157], loss:[1.926/4.797], time:111043.187 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[    7/  157], loss:[2.207/4.427], time:111263.181 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[    8/  157], loss:[2.533/4.190], time:105905.382 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[    9/  157], loss:[1.874/3.933], time:100148.228 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   10/  157], loss:[1.663/3.706], time:92576.630 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   11/  157], loss:[1.574/3.512], time:101641.179 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   12/  157], loss:[1.777/3.368], time:97790.250 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   13/  157], loss:[2.409/3.294], time:102476.926 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   14/  157], loss:[1.950/3.198], time:97842.820 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   15/  157], loss:[1.693/3.097], time:96966.045 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   16/  157], loss:[1.805/3.017], time:92547.941 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   17/  157], loss:[1.796/2.945], time:88268.259 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   18/  157], loss:[1.752/2.879], time:95257.394 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   19/  157], loss:[1.708/2.817], time:93370.251 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   20/  157], loss:[1.700/2.761], time:90240.113 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   21/  157], loss:[1.819/2.716], time:98670.718 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   22/  157], loss:[1.770/2.673], time:100618.842 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   23/  157], loss:[1.808/2.636], time:96571.312 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   24/  157], loss:[1.622/2.593], time:96356.201 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   25/  157], loss:[1.655/2.556], time:100407.366 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   26/  157], loss:[1.708/2.523], time:98735.289 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   27/  157], loss:[1.733/2.494], time:104691.121 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   28/  157], loss:[1.751/2.467], time:113855.401 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   29/  157], loss:[1.670/2.440], time:96398.174 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   30/  157], loss:[1.650/2.414], time:100992.311 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   31/  157], loss:[1.701/2.391], time:94117.254 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   32/  157], loss:[1.621/2.367], time:97505.126 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   33/  157], loss:[1.695/2.346], time:98300.002 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   34/  157], loss:[1.641/2.325], time:94002.499 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   35/  157], loss:[1.674/2.307], time:95433.729 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   36/  157], loss:[1.653/2.289], time:92241.211 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   37/  157], loss:[1.659/2.272], time:99597.531 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   38/  157], loss:[1.627/2.255], time:93185.707 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   39/  157], loss:[1.636/2.239], time:89652.138 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   40/  157], loss:[1.673/2.225], time:91840.338 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   41/  157], loss:[1.634/2.210], time:94370.591 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   42/  157], loss:[1.592/2.196], time:91861.232 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   43/  157], loss:[1.657/2.183], time:90528.898 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   44/  157], loss:[1.717/2.172], time:93622.256 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   45/  157], loss:[1.583/2.159], time:89010.853 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   46/  157], loss:[1.672/2.149], time:89487.011 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   47/  157], loss:[1.646/2.138], time:96944.477 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   48/  157], loss:[1.637/2.128], time:94343.947 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   49/  157], loss:[1.636/2.118], time:95376.733 ms, lr:0.00300\n",
      "Epoch:[  0/ 10], step:[   50/  157], loss:[1.620/2.108], time:96526.745 ms, lr:0.00300\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "total = batch_size\n",
    "print(\"start train...\")\n",
    "epoch= 30\n",
    "\n",
    "for epoch in range(epoch):\n",
    "    with tqdm(total=total) as t:\n",
    "        t.set_description('Epoch %i' % epoch)\n",
    "        model.train(epoch_size,\n",
    "            dataset_train,\n",
    "            callbacks=[ckpt_callback, LossMonitor(lr)],\n",
    "            dataset_sink_mode=False)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其他说明\n",
    "\n",
    "   #### 本次任务由于时间以及电脑设备的局限性，模型未能完全训练完成，但在预期设计以及相关理论研究中，本次任务提出的基于图片和文本两种信息载体建立的多模态多特征的深度学习模型，使用数据集结合市场主体消息、股票价格呈现、股票技术分析等多种渠道，对证券市场股票（以上证50指数为例）的涨跌情况进行预测性分析，可以取得很不错的效果，相较于以往的单模型单类型数据本次任务的设计对于股票预测及量化交易领域具有一定研究及实践意义。\n",
    "   \n",
    "   本次任务由中南财经政法大学信管19级涂宇飞，祁青峰，杨理（排名不分先后）三人合作研究完成，其他更多说明详见README.md"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:MindSpore]",
   "language": "python",
   "name": "conda-env-MindSpore-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
