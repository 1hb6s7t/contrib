{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNz4yVuBMLFn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import mindspore as ms\n",
        "from mindspore import nn\n",
        "from mindspore.common import initializer as init\n",
        "\n",
        "import numpy as np\n",
        "import mindspore.dataset as ds\n",
        "import mindspore.dataset.vision.c_transforms as vision\n",
        "\n",
        "from mindspore import nn, ops\n",
        "\n",
        "ms.set_context(mode=ms.GRAPH_MODE, device_target=\"GPU\")\n",
        "np.random.seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_root = \"./dataset/dataroot\"  # 数据集根目录\n",
        "batch_size = 128          # 批量大小\n",
        "image_size = 64           # 训练图像空间大小\n",
        "nc = 3                    # 图像彩色通道数\n",
        "nz = 100                  # 隐向量的长度\n",
        "ngf = 64                  # 特征图在生成器中的大小\n",
        "ndf = 64                  # 特征图在判别器中的大小\n",
        "num_epochs = 800           # 训练周期数\n",
        "lr = 0.0002               # 学习率\n",
        "beta1 = 0.5               # Adam优化器的beta1超参数"
      ],
      "metadata": {
        "id": "cqXhHzj-Moq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 数据集导入"
      ],
      "metadata": {
        "id": "4PxZ-YzsNVMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset_imagenet(dataset_path):\n",
        "    \"\"\"数据加载\"\"\"\n",
        "    data_set = ds.ImageFolderDataset(dataset_path,\n",
        "                                     num_parallel_workers=4,\n",
        "                                     shuffle=True,\n",
        "                                     decode=True,\n",
        "                                     extensions=['.png'])\n",
        "\n",
        "    # 数据增强操作\n",
        "    transform_img = [\n",
        "        vision.Resize(image_size),\n",
        "        vision.CenterCrop(image_size),\n",
        "        vision.HWC2CHW(),\n",
        "        lambda x: ((x / 255).astype(\"float32\"), np.random.normal(size=(nz, 1, 1)).astype(\"float32\"))]\n",
        "\n",
        "    # 数据映射操作\n",
        "    data_set = data_set.map(input_columns=\"image\",\n",
        "                            num_parallel_workers=4,\n",
        "                            operations=transform_img,\n",
        "                            output_columns=[\"image\", \"latent_code\"],\n",
        "                            column_order=[\"image\", \"latent_code\"])\n",
        "\n",
        "    # 批量操作\n",
        "    data_set = data_set.batch(batch_size)\n",
        "    return data_set\n",
        "\n",
        "# 获取处理后的数据集\n",
        "data = create_dataset_imagenet(data_root)\n",
        "\n",
        "# 获取数据集大小\n",
        "size = data.get_dataset_size()"
      ],
      "metadata": {
        "id": "ltDSi7DTMrd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 模型定义"
      ],
      "metadata": {
        "id": "qSuVgh0ONXBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_t(in_channels, out_channels, kernel_size, stride=1, padding=0, pad_mode=\"pad\"):\n",
        "    \"\"\"定义转置卷积层\"\"\"\n",
        "    weight_init = init.Normal(mean=0, sigma=0.02)\n",
        "    return nn.Conv2dTranspose(in_channels, out_channels,\n",
        "                              kernel_size=kernel_size, stride=stride, padding=padding,\n",
        "                              weight_init=weight_init, has_bias=False, pad_mode=pad_mode)\n",
        "\n",
        "def bn(num_features):\n",
        "    \"\"\"定义BatchNorm2d层\"\"\"\n",
        "    gamma_init = init.Normal(mean=1, sigma=0.02)\n",
        "    return nn.BatchNorm2d(num_features=num_features, gamma_init=gamma_init)"
      ],
      "metadata": {
        "id": "kBd9HWLxMvRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 生成器"
      ],
      "metadata": {
        "id": "YKIXAnsqNf-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Cell):\n",
        "    \"\"\"DCGAN网络生成器\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.generator = nn.SequentialCell()\n",
        "\n",
        "        inchannels = [nz, 512, 256, 128, 64, 3]\n",
        "        outchannels = inchannels[1:]\n",
        "        stride = [1, 2, 2, 2, 2]\n",
        "        padding = [0, 1, 1, 1, 1]\n",
        "        for i in range(len(outchannels)):\n",
        "            self.generator.append(conv_t(inchannels[i], outchannels[i], 4, stride[i], padding[i]))\n",
        "            self.generator.append(bn(outchannels[i]))\n",
        "            if i != len(inchannels)-1:\n",
        "                self.generator.append(nn.ReLU())\n",
        "            else:\n",
        "                self.generator.append(nn.Tanh())\n",
        "\n",
        "    def construct(self, x):\n",
        "        return self.generator(x)"
      ],
      "metadata": {
        "id": "EQ3YbVS7M6iK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 实例化生成器\n",
        "netG = Generator()"
      ],
      "metadata": {
        "id": "ZbbwFfv-NjFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 判别器"
      ],
      "metadata": {
        "id": "Ppp3tEf-NmhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv(in_channels, out_channels, kernel_size, stride=1, padding=0, pad_mode=\"pad\"): # padmode?\n",
        "    \"\"\"定义卷积层\"\"\"\n",
        "    weight_init = init.Normal(mean=0, sigma=0.02)\n",
        "    return nn.Conv2d(in_channels, out_channels,\n",
        "                     kernel_size=kernel_size, stride=stride, padding=padding,\n",
        "                     weight_init=weight_init, has_bias=False, pad_mode=pad_mode)\n",
        "\n"
      ],
      "metadata": {
        "id": "PvURzNAWNjgP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Cell):\n",
        "    \"\"\"DCGAN网络判别器\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.discriminator = nn.SequentialCell()\n",
        "\n",
        "        inchannels = [3, 64, 128, 256, 512]\n",
        "        outchannels = inchannels[1:]\n",
        "        # stride = []\n",
        "        for i in range(len(outchannels)):\n",
        "            self.discriminator.append(conv(inchannels[i], outchannels[i], 4, 2, 1))\n",
        "            if i != 0:\n",
        "                self.discriminator.append(bn(outchannels[i]))\n",
        "            self.discriminator.append(nn.LeakyReLU(0.2))\n",
        "        self.discriminator.append(conv(512, 1, 4, 1))\n",
        "        self.discriminator.append(nn.Sigmoid())\n",
        "\n",
        "    def construct(self, x):\n",
        "        return self.discriminator(x)"
      ],
      "metadata": {
        "id": "zM5pBOFJNoOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 实例化判别器\n",
        "netD = Discriminator()"
      ],
      "metadata": {
        "id": "OrM-pol_Nu_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 模型"
      ],
      "metadata": {
        "id": "4vyw6p-vNzUH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 定义损失函数\n",
        "loss = nn.BCELoss(reduction='mean')\n",
        "\n",
        "class WithLossCellG(nn.Cell):\n",
        "    \"\"\"连接生成器和损失\"\"\"\n",
        "\n",
        "    def __init__(self, netD, netG, loss_fn):\n",
        "        super(WithLossCellG, self).__init__(auto_prefix=True)\n",
        "        self.netD = netD\n",
        "        self.netG = netG\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    def construct(self, latent_code):\n",
        "        \"\"\"构建生成器损失计算结构\"\"\"\n",
        "        fake_data = self.netG(latent_code)\n",
        "        out = self.netD(fake_data)\n",
        "        label_real = ops.OnesLike()(out)\n",
        "        loss = self.loss_fn(out, label_real)\n",
        "        return loss\n",
        "\n",
        "class WithLossCellD(nn.Cell):\n",
        "    \"\"\"连接判别器和损失\"\"\"\n",
        "\n",
        "    def __init__(self, netD, netG, loss_fn):\n",
        "        super(WithLossCellD, self).__init__(auto_prefix=True)\n",
        "        self.netD = netD\n",
        "        self.netG = netG\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    def construct(self, real_data, latent_code):\n",
        "        \"\"\"构建判别器损失计算结构\"\"\"\n",
        "        out_real = self.netD(real_data)\n",
        "        label_real = ops.OnesLike()(out_real)\n",
        "        loss_real = self.loss_fn(out_real, label_real)\n",
        "\n",
        "        fake_data = self.netG(latent_code)\n",
        "        fake_data = ops.stop_gradient(fake_data)\n",
        "        out_fake = self.netD(fake_data)\n",
        "        label_fake = ops.ZerosLike()(out_fake)\n",
        "        loss_fake = self.loss_fn(out_fake, label_fake)\n",
        "        return loss_real + loss_fake"
      ],
      "metadata": {
        "id": "idafZ0g_NvZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fixed_noise = ms.Tensor(np.random.randn(64, nz, 1, 1), dtype=ms.float32)\n",
        "\n",
        "# 为生成器和判别器设置优化器\n",
        "optimizerD = nn.Adam(netD.trainable_params(), learning_rate=lr, beta1=beta1)\n",
        "optimizerG = nn.Adam(netG.trainable_params(), learning_rate=lr, beta1=beta1)"
      ],
      "metadata": {
        "id": "6oNi8jX0N7ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DCGAN(nn.Cell):\n",
        "    \"\"\"定义DCGAN网络\"\"\"\n",
        "\n",
        "    def __init__(self, myTrainOneStepCellForD, myTrainOneStepCellForG):\n",
        "        super(DCGAN, self).__init__(auto_prefix=True)\n",
        "        self.myTrainOneStepCellForD = myTrainOneStepCellForD\n",
        "        self.myTrainOneStepCellForG = myTrainOneStepCellForG\n",
        "\n",
        "    def construct(self, real_data, latent_code):\n",
        "        output_D = self.myTrainOneStepCellForD(real_data, latent_code).view(-1)\n",
        "        netD_loss = output_D.mean()\n",
        "        output_G = self.myTrainOneStepCellForG(latent_code).view(-1)\n",
        "        netG_loss = output_G.mean()\n",
        "        return netD_loss, netG_loss"
      ],
      "metadata": {
        "id": "8wsfcCwCN_10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 实例化WithLossCell\n",
        "netD_with_criterion = WithLossCellD(netD, netG, loss)\n",
        "netG_with_criterion = WithLossCellG(netD, netG, loss)\n",
        "\n",
        "# 实例化TrainOneStepCell\n",
        "myTrainOneStepCellForD = nn.TrainOneStepCell(netD_with_criterion, optimizerD)\n",
        "myTrainOneStepCellForG = nn.TrainOneStepCell(netG_with_criterion, optimizerG)\n",
        "\n",
        "# 实例化DCGAN网络\n",
        "dcgan = DCGAN(myTrainOneStepCellForD, myTrainOneStepCellForG)\n",
        "dcgan.set_train()"
      ],
      "metadata": {
        "id": "KjxRxyFlOB12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 模型训练"
      ],
      "metadata": {
        "id": "xmSz7eOjOOL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 创建迭代器\n",
        "data_loader = data.create_dict_iterator(output_numpy=True, num_epochs=num_epochs)\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "image_list = []\n",
        "\n",
        "# 开始循环训练\n",
        "print(\"Starting Training Loop...\")\n",
        "ms.load_checkpoint(\"Generator{}.ckpt\".format(ngf), netG)\n",
        "ms.load_checkpoint(\"Discriminator{}.ckpt\".format(ndf), netD)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    # 为每轮训练读入数据\n",
        "    for i, d in enumerate(data_loader):\n",
        "#        if(epoch < 10):\n",
        "#            continue\n",
        "        real_data = ms.Tensor(d['image'])\n",
        "        latent_code = ms.Tensor(d[\"latent_code\"])\n",
        "        netD_loss, netG_loss = dcgan(real_data, latent_code)\n",
        "        if i % 50 == 0 or i == size - 1:\n",
        "            # 输出训练记录\n",
        "            print('[%2d/%d][%3d/%d]   Loss_D:%7.4f  Loss_G:%7.4f' % (\n",
        "                epoch + 1, num_epochs, i + 1, size, netD_loss.asnumpy(), netG_loss.asnumpy()))\n",
        "        D_losses.append(netD_loss.asnumpy())\n",
        "        G_losses.append(netG_loss.asnumpy())\n",
        "\n",
        "    # 每个epoch结束后，使用生成器生成一组图片\n",
        "    if epoch % 10 == 0:\n",
        "        img = netG(fixed_noise)\n",
        "        image_list.append(img.transpose(0, 2, 3, 1).asnumpy())\n",
        "\n",
        "    # 保存网络模型参数为ckpt文件\n",
        "    if epoch % 30 == 0 or epoch == num_epochs - 1:\n",
        "        ms.save_checkpoint(netG, \"Generator{}_e{}.ckpt\".format(ngf, epoch))\n",
        "        ms.save_checkpoint(netD, \"Discriminator{}_e{}.ckpt\".format(ndf, epoch))"
      ],
      "metadata": {
        "id": "J6H7qDAWOGcY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 结果处理"
      ],
      "metadata": {
        "id": "-QZTLUmsOThy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img64 = netG(fixed_noise).transpose(0, 2, 3, 1).asnumpy()\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "fig = plt.figure(figsize=(8, 3), dpi=120)\n",
        "images = []\n",
        "for i in range(3):\n",
        "    images.append(np.concatenate((img64[i * 8:(i + 1) * 8]), axis=1))\n",
        "img = np.clip(np.concatenate((images[:]), axis=0), 0, 1)\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(img)\n",
        "plt.imsave(\"result.png\", img)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "\n",
        "def showGif(image_list):\n",
        "    show_list = []\n",
        "    fig = plt.figure(figsize=(8, 3), dpi=120)\n",
        "    for epoch in range(len(image_list)):\n",
        "        images = []\n",
        "        for i in range(3):\n",
        "            row = np.concatenate((image_list[epoch][i * 8:(i + 1) * 8]), axis=1)\n",
        "            images.append(row)\n",
        "        img = np.clip(np.concatenate((images[:]), axis=0), 0, 1)\n",
        "        plt.axis(\"off\")\n",
        "        show_list.append([plt.imshow(img)])\n",
        "\n",
        "    ani = animation.ArtistAnimation(fig, show_list, interval=1000, repeat_delay=1000, blit=True)\n",
        "    ani.save('./dcgan.gif', writer='pillow', fps=1)\n",
        "showGif(image_list)"
      ],
      "metadata": {
        "id": "i2f4dmt6OSz8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
